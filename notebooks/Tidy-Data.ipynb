{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A [tidy dataset](http://vita.had.co.nz/papers/tidy-data.html) should look like this:\n",
    "\n",
    "- each column represents unique variables\n",
    "- each row represents observations\n",
    "- form a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pd.melt() to transform a \"tidy\" table, into an \"untidy\" table.\n",
    "# https://campus.datacamp.com/courses/cleaning-data-in-python/tidying-data-for-analysis?ex=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pd.pivot(), or pd.pivot_table() - to transform a \"untidy\" table, into an \"tidy\" table.\n",
    "# https://campus.datacamp.com/courses/cleaning-data-in-python/tidying-data-for-analysis?ex=5\n",
    "# Note: \n",
    "#  pd.pivot(): errors if duplicate entries. But can be fixed\n",
    "#  e.g. taking average of duplicate values, with pd.pivot_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat([df1, df2, df3,...], ignore_index=True, axis=0)\n",
    "# use axis=0 for row wise concat (default)\n",
    "# use axis=1 for column wise concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply apply apply! lambda lambda lambda! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "# csv_files = glob.glob(\"*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.merge(left=lkv, right=rkv, left_on=\"name\", right_on=\"customer_name\")\n",
    "# pd.merge(left=lkv, right=rkv, on=\"common_name\")\n",
    "# one-to-one\n",
    "# many-to-one\n",
    "# one-to-many\n",
    "# many-to-many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# say a column is supposed to be all numeric. but some values has missing values assigned as \"-\" in CSV.\n",
    "# so that column gets imported as string.\n",
    "# to correct this we can do this:\n",
    "\n",
    "# df.loc[:, \"col1\"] = pd.to_numeric(df.loc[:, \"col1\"], errors=\"coerce\")\n",
    "\n",
    "\n",
    "# alternatively use pd.loc[:, \"col1\"].astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas datatypes:\n",
    "#   - object is encoded as string. need to convert to the appropriate type.\n",
    "#   - category saves memory for small number of unique values. Used by other packages like datashader for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write the lambda function using replace (remove positive $)\n",
    "# tips['total_dollar_replace'] = tips['total_dollar'].apply(lambda x: x.replace('$', ''))\n",
    "\n",
    "# # Write the lambda function using regular expressions (extract positive digit)\n",
    "# tips['total_dollar_re'] = tips['total_dollar'].apply(lambda x: re.findall('\\d+\\.\\d+', x)[0])\n",
    "\n",
    "# # Print the head of tips\n",
    "# print(tips.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop_duplicates()\n",
    "# df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_val = df[\"col\"].mean()\n",
    "# mean_val = np.mean(df[\"col\"])\n",
    "# df.loc[:, 'col1'] = df.loc[:, 'col1'].fillna(mean_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assert that there are no missing values\n",
    "# assert pd.notnull(ebola).all().all()\n",
    "\n",
    "# # Assert that all values are >= 0\n",
    "# assert (ebola >= 0).all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either:\n",
    "  \n",
    "#   - combine then clean,\n",
    "#   - clean then combine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
